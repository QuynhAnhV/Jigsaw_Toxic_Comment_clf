{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import sklearn.naive_bayes\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "## Self Imports\n",
    "from src.utils import *\n",
    "from nltk.tokenize import word_tokenize, regexp_tokenize\n",
    "from numpy import argmax\n",
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        module\n",
       "\u001b[1;31mString form:\u001b[0m <module 'sklearn.naive_bayes' from 'C:\\\\Users\\\\vuquy\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\naive_bayes.py'>\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\vuquy\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "The :mod:`sklearn.naive_bayes` module implements Naive Bayes algorithms. These\n",
       "are supervised learning methods based on applying Bayes' theorem with strong\n",
       "(naive) feature independence assumptions.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?sklearn.naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = join('..', 'Data', 'Raw', 'train.csv')\n",
    "test_path = join('..', 'Data', 'Raw', 'test.csv')\n",
    "test_labels_path = join('..', 'Data', 'Raw', 'test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_test = df_test['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Yo bitch Ja Rule is more succesful then you'll...\n",
       "1    == From RfC == \\n\\n The title is fine as it is...\n",
       "2    \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3    :If you have a look back at the source, the in...\n",
       "4            I don't anonymously edit articles at all.\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = df['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.drop('comment_text', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  0000997932d777bf      0             0        0       0       0   \n",
       "1  000103f0d9cfb60f      0             0        0       0       0   \n",
       "2  000113f07ec002fd      0             0        0       0       0   \n",
       "3  0001b41b1c6bb37e      0             0        0       0       0   \n",
       "4  0001d958c54c6e35      0             0        0       0       0   \n",
       "\n",
       "   identity_hate  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09584448302009764"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['toxic'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(min_df = 0.001, stop_words='english')\n",
    "X = vectorizer1.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '01', '02', '03']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer1.get_feature_names()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 3647)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.413787841796875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.data.nbytes/1024/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '01', '02', '03', '04', '05', '06', '07', '08']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial NB with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr, xte, ytr, yte = train_test_split(X, labels['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(xtr, ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = clf.predict(xtr)\n",
    "train_actual = ytr.values\n",
    "train_error = np.mean(abs(train_pred - train_actual))\n",
    "accuracy = 1 - train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9433396280018048"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.691886250978346"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(train_actual, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9700681278251786"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity(train_actual, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9673408060174772"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_predictive_value(train_actual, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7107378953010541"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(train_actual, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7011853875644473"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(train_actual, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = clf.predict(xte)\n",
    "test_actual = yte.values\n",
    "test_error = np.mean(abs(test_pred - test_actual))\n",
    "t_accuracy = 1 - test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9400897400546462"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6669301712779974"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(test_actual, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9688071361294255"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity(test_actual, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9651175626448836"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_predictive_value(test_actual, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6920973475526387"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(test_actual, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6792807300053677"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_actual, test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(min_df =0.001, stop_words = 'english')\n",
    "Y = vectorizer2.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 3647)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '01', '02', '03', '04', '05', '06', '07']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer2.get_feature_names()[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial NB with Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1, y2, z1, z2 = train_test_split(Y, labels['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = MultinomialNB()\n",
    "clf1.fit(y1, z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred1 = clf1.predict(y1)\n",
    "train_actual1 = z1.values\n",
    "train_error1 = np.mean(abs(train_pred1 - train_actual1))\n",
    "accuracy1 = 1 - train_error1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9481107638830862"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = pd.DataFrame(['You Suck', 'Hello Friends'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_X = vectorizer2.transform(testing_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = clf1.predict_proba(testing_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04411346, 0.95588654],\n",
       "       [0.85028361, 0.14971639]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9558865368625948"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558865368625948\n",
      "0.14971638503881088\n"
     ]
    }
   ],
   "source": [
    "for x in range(len(pred_result)):\n",
    "    m = pred_result[x, 1]\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9474343869851853"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1 = clf.predict(y2)\n",
    "test_actual1 = z2.values\n",
    "test_error1 = np.mean(abs(test_pred1 - test_actual1))\n",
    "t_accuracy1 = 1 - test_error1\n",
    "t_accuracy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4885057471264368"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity(test_actual1, test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961458477748509"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity(test_actual1, test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9483159117305459"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_predictive_value(test_actual1, test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9308113489298159"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(test_actual1, test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6407401062189482"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_actual1, test_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on different lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Evaluation metrics for toxic: \n",
      "**On training set\n",
      "Accuracy: 0.9482695232206421, Sensitivity: 0.49773991655076494, Specificity: 0.9961820770240538, NPV: 0.9491099974458116, Precison: 0.9327251995438997, F1 Score: 0.6490959587371762\n",
      "**On test set\n",
      "Accuracy: 0.947810392800742, Sensitivity: 0.4857519788918206, Specificity: 0.9963160956153229, NPV: 0.9486009652153274, Precison: 0.9326241134751773, F1 Score: 0.6387925052047189\n",
      "*Evaluation metrics for severe_toxic: \n",
      "**On training set\n",
      "Accuracy: 0.9906081318203847, Sensitivity: 0.195162635529608, Specificity: 0.9986579900235485, NPV: 0.9919101311983904, Precison: 0.5954198473282443, F1 Score: 0.29396984924623115\n",
      "**On test set\n",
      "Accuracy: 0.9906499887198256, Sensitivity: 0.19444444444444445, Specificity: 0.9986328075550042, NPV: 0.9919772647251144, Precison: 0.5877862595419847, F1 Score: 0.2922201138519924\n",
      "*Evaluation metrics for obscene: \n",
      "**On training set\n",
      "Accuracy: 0.973587459683484, Sensitivity: 0.5480387486104494, Specificity: 0.9972217567317275, NPV: 0.9754468907447029, Precison: 0.9163568773234201, F1 Score: 0.6858789625360231\n",
      "**On test set\n",
      "Accuracy: 0.9718496979419948, Sensitivity: 0.5357806691449815, Specificity: 0.9967144484777828, NPV: 0.9741298943443132, Precison: 0.9028974158183242, F1 Score: 0.6724992709244678\n",
      "*Evaluation metrics for threat: \n",
      "**On training set\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-ef84683a0c3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'*Evaluation metrics for {label}: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**On training set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Accuracy: {accuracy}, Sensitivity: {sensitivity(train_actual, train_pred)}, Specificity: {specificity(train_actual, train_pred)}, NPV: {negative_predictive_value(train_actual, train_pred)}, Precison: {precision(train_actual, train_pred)}, F1 Score: {f1_score(train_actual, train_pred)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#Evaluation on test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\DataScience\\Jigsaw_Toxic_Comment_clf\\src\\utils.py\u001b[0m in \u001b[0;36mprecision\u001b[1;34m(y, y_pred)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mpositive_predictive_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\DataScience\\Jigsaw_Toxic_Comment_clf\\src\\utils.py\u001b[0m in \u001b[0;36mpositive_predictive_value\u001b[1;34m(y, y_pred)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mTP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mFP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mprec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "for label in labels.drop('id', axis = 1).columns:\n",
    "    xtr, xte, ytr, yte = train_test_split(Y, labels[label])\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(xtr, ytr)\n",
    "    \n",
    "    # Evaluation on training set\n",
    "    train_pred = mnb.predict(xtr)\n",
    "    train_actual = ytr.values\n",
    "    train_error = np.mean(abs(train_pred - train_actual))\n",
    "    accuracy = 1 - train_error\n",
    "    print(f'*Evaluation metrics for {label}: ')\n",
    "    print('**On training set')\n",
    "    print(f'Accuracy: {accuracy}, Sensitivity: {sensitivity(train_actual, train_pred)}, Specificity: {specificity(train_actual, train_pred)}, NPV: {negative_predictive_value(train_actual, train_pred)}, Precison: {precision(train_actual, train_pred)}, F1 Score: {f1_score(train_actual, train_pred)}')\n",
    "    \n",
    "    #Evaluation on test set\n",
    "    test_pred = mnb.predict(xte)\n",
    "    test_actual = yte.values\n",
    "    test_error = np.mean(abs(test_pred - test_actual))\n",
    "    t_accuracy = 1 - test_error\n",
    "    t_accuracy\n",
    "    print('**On test set')\n",
    "    print(f'Accuracy: {t_accuracy}, Sensitivity: {sensitivity(test_actual, test_pred)}, Specificity: {specificity(test_actual, test_pred)}, NPV: {negative_predictive_value(test_actual, test_pred)}, Precison: {precision(test_actual, test_pred)}, F1 Score: {f1_score(test_actual, test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  0000997932d777bf      0             0        0       0       0   \n",
       "1  000103f0d9cfb60f      0             0        0       0       0   \n",
       "2  000113f07ec002fd      0             0        0       0       0   \n",
       "3  0001b41b1c6bb37e      0             0        0       0       0   \n",
       "4  0001d958c54c6e35      0             0        0       0       0   \n",
       "\n",
       "   identity_hate  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gen_feats(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate features for training and testing\n",
    "    \n",
    "    Args:\n",
    "        args[0]: features (comment_text) of training set\n",
    "        args[1]: features of test set\n",
    "        args[2]: chosen type of Vectorizer\n",
    "        kwargs: hyper parameters used for Vectorizer\n",
    "        \n",
    "    Returns:\n",
    "        Features for training (X) and testing (Xte)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    vectorizer = args[2](kwargs)\n",
    "    X = vectorizer.fit_transform(args[0])\n",
    "    Xte = vectorizer.transform(args[1])\n",
    "    return X, Xte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worked\n",
    "# _gen_feats(feature, feats_test, TfidfVectorizer, vect_kwargs = {'min_df':0.001, 'stop_words':'english'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_y_dropcols(*args):\n",
    "    \"\"\"\n",
    "    Extracts all label fields & ID.\n",
    "    \n",
    "    Args:\n",
    "        arg[0]: Raw training dataframe with labels, ID, & comment text\n",
    "        arg[1]: columns to drop \n",
    "        arg[2]: label to predict on\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "  \n",
    "    # Save dropped columns into new variable before dropping\n",
    "    cmt_id = args[0][args[1]]\n",
    "    \n",
    "    # Create new dataframe without dropped columns\n",
    "\n",
    "    for label in args[0].columns:\n",
    "        y = args[0][args[2]]\n",
    "    \n",
    "    return y, cmt_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worked\n",
    "# _get_y_dropcols(labels, 'id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Preprocessing the raw data to get data ready to be trained and tested\n",
    "    \n",
    "    Args:\n",
    "        args[0]: features (comment_text) of training set\n",
    "        args[1]: features of test set\n",
    "        args[2]: chosen type of Vectorizer\n",
    "        args[3]: labels of training set\n",
    "        args[4]: columns to drop from label (id)\n",
    "        args[5]: label to predict on\n",
    "        kwargs: hyper parameters used for Vectorizer\n",
    "        \n",
    "    Returns:\n",
    "        Training data (X, y), test data(Xte), dropped columns\n",
    "        \n",
    "    \"\"\"\n",
    "        \n",
    "    X, Xte = _gen_feats(args[0], args[1], args[2], kwargs)\n",
    "    y, cmt_id = _get_y_dropcols(args[3], args[4], args[5])\n",
    "        \n",
    "    return X, Xte, y, cmt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worked\n",
    "# preprocessing(feature, feats_test, TfidfVectorizer, labels, 'id', \n",
    "#               vect_kwargs = {'min_df':0.001, 'stop_words':'english'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gen_model(X, y, model_type):\n",
    "    \"\"\"\n",
    "    \n",
    "    Generate a fitted model ready to make prediction\n",
    "    \n",
    "    X: training features (comment_text)\n",
    "    y: training lables\n",
    "    \n",
    "    Returns:\n",
    "        A model ready for predicting test set\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize model type with \"model\"\n",
    "    model = model_type()\n",
    "    # Fitting model with training data X, y\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U better work man\n",
    "# _gen_model(X, y, MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gen_preds(Xte, model):\n",
    "    \"\"\"\n",
    "    Make prediction on test set and return the predicted probability for the testing label\n",
    "    \n",
    "    Args: \n",
    "        Xte: test data set with only comment_text column\n",
    "        model: fitted model generated in gen_model\n",
    "        \n",
    "    Returns\n",
    "        (float) \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    pred_result = model.predict_proba(Xte)\n",
    "    prob = pred_result[:, 1]\n",
    "    return prob       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_transform(raw_output, *args):\n",
    "\n",
    "    \"\"\"\n",
    "    Transform raw output to appropriate form for submission \n",
    "    \n",
    "    Args:\n",
    "        raw_output:(dataframe) output from _gen_preds function\n",
    "        args: columns' name\n",
    "        \n",
    "    Return:\n",
    "        Transformed dataframe ready for converting to csv \n",
    "        \n",
    "    \"\"\"\n",
    "    # Transpose the output so labels are columns and comments are rows\n",
    "    trans_df = raw_output.T\n",
    "    # Rename all columns\n",
    "    trans_df.columns = args\n",
    "    # Insert the id column from df_test at position 0 to the left \n",
    "    trans_df.insert(0, 'id', df_test['id'], True)\n",
    "    # Reset index to start from 1 instead of 0\n",
    "    trans_df.index += 1 \n",
    "    \n",
    "    return trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a path to submission file\n",
    "save_path01 = join('..', 'Results', 'simple_subm01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gen_kaggle_sub(feature, feats_test, lbs, save_path):\n",
    "    \"\"\"\n",
    "    Generate a csv file to submit to Kaggle\n",
    "    \n",
    "    Args:\n",
    "        lbs: labels of orginal df\n",
    "        save_path: path to save location\n",
    "        \n",
    "    Returns:\n",
    "        csv file\n",
    "        \n",
    "    \"\"\"\n",
    "    # Preprocessing the raw data to get data ready to be trained and tested\n",
    "    lb_proba = []\n",
    "    for label in lbs.columns:\n",
    "        X, Xte, y, cmt_id = preprocessing(feature, feats_test, TfidfVectorizer, labels, 'id', label, \n",
    "                                          vect_kwargs = {'min_df':0.001, 'stop_words':'english'})\n",
    "    \n",
    "        # Generate a fitted model ready to make prediction\n",
    "        model = _gen_model(X, y, MultinomialNB)\n",
    "        # Make prediction on test set and return the predicted probability for the testing label\n",
    "        prob = _gen_preds(Xte, model)\n",
    "        lb_proba.append(prob)\n",
    "    \n",
    "    # Transform the output array to dataframe\n",
    "    raw_pred_df = pd.DataFrame(lb_proba)\n",
    "    \n",
    "    # Transform to appropriate form for submission \n",
    "    sub_df = output_transform(raw_pred_df,\n",
    "                              'toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate')\n",
    "    \n",
    "    sub_df.to_csv(save_path, index = False)\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.401214</td>\n",
       "      <td>4.801955e-07</td>\n",
       "      <td>2.293768e-02</td>\n",
       "      <td>3.035624e-09</td>\n",
       "      <td>6.842720e-03</td>\n",
       "      <td>4.848761e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>1.126907e-06</td>\n",
       "      <td>1.285176e-04</td>\n",
       "      <td>1.265841e-07</td>\n",
       "      <td>1.037182e-04</td>\n",
       "      <td>1.525776e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.110318</td>\n",
       "      <td>7.497661e-03</td>\n",
       "      <td>6.060326e-02</td>\n",
       "      <td>1.944498e-03</td>\n",
       "      <td>5.686125e-02</td>\n",
       "      <td>7.324074e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>2.055300e-09</td>\n",
       "      <td>4.193695e-06</td>\n",
       "      <td>7.595696e-11</td>\n",
       "      <td>3.228442e-06</td>\n",
       "      <td>1.559327e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>2.354547e-05</td>\n",
       "      <td>1.500915e-03</td>\n",
       "      <td>2.695010e-06</td>\n",
       "      <td>1.224030e-03</td>\n",
       "      <td>1.932940e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>2.649962e-08</td>\n",
       "      <td>2.843496e-05</td>\n",
       "      <td>2.190758e-09</td>\n",
       "      <td>2.418763e-05</td>\n",
       "      <td>3.822227e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>9.143020e-10</td>\n",
       "      <td>3.753479e-06</td>\n",
       "      <td>2.871155e-11</td>\n",
       "      <td>2.464680e-06</td>\n",
       "      <td>9.004787e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>0.060142</td>\n",
       "      <td>3.967158e-05</td>\n",
       "      <td>8.073634e-03</td>\n",
       "      <td>5.068992e-06</td>\n",
       "      <td>7.758652e-03</td>\n",
       "      <td>4.161255e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>9.945701e-10</td>\n",
       "      <td>4.062479e-06</td>\n",
       "      <td>6.163175e-11</td>\n",
       "      <td>2.477330e-06</td>\n",
       "      <td>1.468281e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>6.547442e-09</td>\n",
       "      <td>7.491110e-06</td>\n",
       "      <td>6.159895e-10</td>\n",
       "      <td>5.475115e-06</td>\n",
       "      <td>9.274395e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002eadc3b301559</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>8.607847e-09</td>\n",
       "      <td>8.376933e-05</td>\n",
       "      <td>4.346382e-10</td>\n",
       "      <td>3.948727e-05</td>\n",
       "      <td>1.900641e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>3.450315e-09</td>\n",
       "      <td>1.069713e-05</td>\n",
       "      <td>1.779022e-10</td>\n",
       "      <td>7.646419e-06</td>\n",
       "      <td>7.251321e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003806b11932181</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>6.409742e-10</td>\n",
       "      <td>2.027266e-06</td>\n",
       "      <td>3.137825e-11</td>\n",
       "      <td>1.205619e-06</td>\n",
       "      <td>5.328110e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>4.938336e-08</td>\n",
       "      <td>3.452524e-05</td>\n",
       "      <td>2.992070e-09</td>\n",
       "      <td>1.889621e-05</td>\n",
       "      <td>6.576210e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>8.643334e-11</td>\n",
       "      <td>4.761840e-07</td>\n",
       "      <td>4.216301e-12</td>\n",
       "      <td>2.985132e-07</td>\n",
       "      <td>1.051656e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000634272d0d44eb</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>6.493673e-06</td>\n",
       "      <td>7.395913e-04</td>\n",
       "      <td>1.117532e-06</td>\n",
       "      <td>6.316192e-04</td>\n",
       "      <td>9.959475e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000663aff0fffc80</td>\n",
       "      <td>0.034875</td>\n",
       "      <td>4.397730e-04</td>\n",
       "      <td>1.235974e-02</td>\n",
       "      <td>7.057744e-05</td>\n",
       "      <td>1.078983e-02</td>\n",
       "      <td>4.927785e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000689dd34e20979</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>7.692581e-08</td>\n",
       "      <td>7.174434e-05</td>\n",
       "      <td>6.084539e-09</td>\n",
       "      <td>5.386529e-05</td>\n",
       "      <td>1.394492e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000834769115370c</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>2.899354e-12</td>\n",
       "      <td>1.812908e-07</td>\n",
       "      <td>5.221108e-14</td>\n",
       "      <td>8.443901e-08</td>\n",
       "      <td>4.096484e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000844b52dee5f3f</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>6.720759e-06</td>\n",
       "      <td>1.145694e-03</td>\n",
       "      <td>3.610099e-07</td>\n",
       "      <td>9.506065e-04</td>\n",
       "      <td>5.387312e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00084da5d4ead7aa</td>\n",
       "      <td>0.013630</td>\n",
       "      <td>5.500105e-05</td>\n",
       "      <td>3.404537e-03</td>\n",
       "      <td>8.153383e-06</td>\n",
       "      <td>2.683688e-03</td>\n",
       "      <td>4.128559e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00091c35fa9d0465</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>9.759446e-06</td>\n",
       "      <td>9.071497e-04</td>\n",
       "      <td>1.673874e-06</td>\n",
       "      <td>7.593932e-04</td>\n",
       "      <td>2.045658e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000968ce11f5ee34</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>4.066731e-08</td>\n",
       "      <td>9.450634e-05</td>\n",
       "      <td>1.931657e-09</td>\n",
       "      <td>7.171904e-05</td>\n",
       "      <td>6.780058e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0009734200a85047</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>3.421008e-07</td>\n",
       "      <td>5.777983e-05</td>\n",
       "      <td>3.754767e-08</td>\n",
       "      <td>4.473262e-05</td>\n",
       "      <td>4.604294e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00097b6214686db5</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>1.039569e-07</td>\n",
       "      <td>2.632847e-04</td>\n",
       "      <td>6.064824e-09</td>\n",
       "      <td>1.549245e-04</td>\n",
       "      <td>1.613602e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0009aef4bd9e1697</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.786042e-10</td>\n",
       "      <td>6.220546e-07</td>\n",
       "      <td>2.966246e-11</td>\n",
       "      <td>4.557426e-07</td>\n",
       "      <td>6.199944e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000a02d807ae0254</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>3.318503e-07</td>\n",
       "      <td>1.683112e-04</td>\n",
       "      <td>3.735080e-08</td>\n",
       "      <td>1.084763e-04</td>\n",
       "      <td>5.204718e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000a6c6d4e89b9bc</td>\n",
       "      <td>0.022232</td>\n",
       "      <td>1.435713e-04</td>\n",
       "      <td>4.948179e-03</td>\n",
       "      <td>2.648273e-05</td>\n",
       "      <td>4.022649e-03</td>\n",
       "      <td>1.602446e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000bafe2080bba82</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>1.270082e-07</td>\n",
       "      <td>1.510442e-04</td>\n",
       "      <td>6.017970e-09</td>\n",
       "      <td>1.330725e-04</td>\n",
       "      <td>6.311305e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>000bf0a9894b2807</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>3.135608e-10</td>\n",
       "      <td>1.688038e-06</td>\n",
       "      <td>1.210374e-11</td>\n",
       "      <td>1.268879e-06</td>\n",
       "      <td>5.214625e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153135</th>\n",
       "      <td>fff3ae2e177b6bb3</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>1.749234e-09</td>\n",
       "      <td>6.331375e-06</td>\n",
       "      <td>8.362236e-11</td>\n",
       "      <td>4.605520e-06</td>\n",
       "      <td>3.057887e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153136</th>\n",
       "      <td>fff4109e837f7acc</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>7.577678e-06</td>\n",
       "      <td>6.145186e-04</td>\n",
       "      <td>7.277430e-07</td>\n",
       "      <td>4.150901e-04</td>\n",
       "      <td>8.769886e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153137</th>\n",
       "      <td>fff4373a81ef9f2a</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.026127e-09</td>\n",
       "      <td>3.586931e-06</td>\n",
       "      <td>4.946327e-11</td>\n",
       "      <td>2.522530e-06</td>\n",
       "      <td>1.894806e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153138</th>\n",
       "      <td>fff460574ddbcd80</td>\n",
       "      <td>0.009341</td>\n",
       "      <td>7.012262e-06</td>\n",
       "      <td>1.376750e-03</td>\n",
       "      <td>8.310382e-07</td>\n",
       "      <td>1.092258e-03</td>\n",
       "      <td>1.077599e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153139</th>\n",
       "      <td>fff4fc0a1555be5c</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1.560590e-08</td>\n",
       "      <td>1.777961e-05</td>\n",
       "      <td>8.412163e-10</td>\n",
       "      <td>1.193501e-05</td>\n",
       "      <td>2.156232e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153140</th>\n",
       "      <td>fff5b9bb944d634c</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>2.293349e-07</td>\n",
       "      <td>1.719517e-04</td>\n",
       "      <td>9.629429e-09</td>\n",
       "      <td>1.157330e-04</td>\n",
       "      <td>3.046453e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153141</th>\n",
       "      <td>fff5c4a77fe0c05f</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>2.495729e-07</td>\n",
       "      <td>1.458753e-04</td>\n",
       "      <td>1.871546e-08</td>\n",
       "      <td>9.190113e-05</td>\n",
       "      <td>3.161311e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153142</th>\n",
       "      <td>fff5fb61bd637c82</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>2.059179e-09</td>\n",
       "      <td>2.448874e-06</td>\n",
       "      <td>1.531766e-10</td>\n",
       "      <td>1.598501e-06</td>\n",
       "      <td>2.456769e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153143</th>\n",
       "      <td>fff69311f306df44</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>5.560698e-05</td>\n",
       "      <td>1.389613e-03</td>\n",
       "      <td>8.751502e-06</td>\n",
       "      <td>1.799283e-03</td>\n",
       "      <td>6.912105e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153144</th>\n",
       "      <td>fff6ad63666fb304</td>\n",
       "      <td>0.620878</td>\n",
       "      <td>1.893717e-03</td>\n",
       "      <td>2.382147e-01</td>\n",
       "      <td>3.253189e-05</td>\n",
       "      <td>1.116350e-01</td>\n",
       "      <td>5.117248e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153145</th>\n",
       "      <td>fff7159b3ee95618</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>5.647543e-08</td>\n",
       "      <td>6.090402e-05</td>\n",
       "      <td>2.842595e-09</td>\n",
       "      <td>3.605537e-05</td>\n",
       "      <td>8.551762e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153146</th>\n",
       "      <td>fff718ffe5f05559</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1.975964e-07</td>\n",
       "      <td>5.063397e-05</td>\n",
       "      <td>2.008588e-08</td>\n",
       "      <td>4.032894e-05</td>\n",
       "      <td>3.424879e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153147</th>\n",
       "      <td>fff7fc22a0cdccd3</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.364876e-11</td>\n",
       "      <td>4.145574e-07</td>\n",
       "      <td>1.202532e-12</td>\n",
       "      <td>2.698844e-07</td>\n",
       "      <td>4.959495e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153148</th>\n",
       "      <td>fff83b80284d8440</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>7.437673e-06</td>\n",
       "      <td>9.055402e-04</td>\n",
       "      <td>4.436586e-07</td>\n",
       "      <td>8.235147e-04</td>\n",
       "      <td>4.918661e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153149</th>\n",
       "      <td>fff8ef316d0c6990</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>8.656997e-07</td>\n",
       "      <td>1.752051e-04</td>\n",
       "      <td>9.904686e-08</td>\n",
       "      <td>1.534591e-04</td>\n",
       "      <td>1.257561e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>fff8f521a7dbcd47</td>\n",
       "      <td>0.042013</td>\n",
       "      <td>8.628015e-05</td>\n",
       "      <td>5.418150e-03</td>\n",
       "      <td>6.060350e-06</td>\n",
       "      <td>5.061413e-03</td>\n",
       "      <td>4.552823e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>8.011449e-10</td>\n",
       "      <td>7.100787e-06</td>\n",
       "      <td>2.510854e-11</td>\n",
       "      <td>4.227538e-06</td>\n",
       "      <td>1.175081e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153152</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>0.117855</td>\n",
       "      <td>2.478148e-04</td>\n",
       "      <td>2.472171e-02</td>\n",
       "      <td>2.071025e-05</td>\n",
       "      <td>1.810628e-02</td>\n",
       "      <td>1.684519e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153153</th>\n",
       "      <td>fff9fa508f400ee6</td>\n",
       "      <td>0.017155</td>\n",
       "      <td>1.440540e-05</td>\n",
       "      <td>3.599483e-03</td>\n",
       "      <td>1.264856e-06</td>\n",
       "      <td>1.668745e-03</td>\n",
       "      <td>1.219323e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>fffa3fae1890b40a</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>1.135558e-08</td>\n",
       "      <td>6.008503e-05</td>\n",
       "      <td>4.808189e-10</td>\n",
       "      <td>3.897803e-05</td>\n",
       "      <td>1.503420e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>0.032229</td>\n",
       "      <td>1.399145e-05</td>\n",
       "      <td>2.324078e-03</td>\n",
       "      <td>1.066581e-06</td>\n",
       "      <td>2.334242e-03</td>\n",
       "      <td>2.803831e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>0.218863</td>\n",
       "      <td>5.479940e-06</td>\n",
       "      <td>2.239193e-02</td>\n",
       "      <td>7.624137e-08</td>\n",
       "      <td>9.388320e-03</td>\n",
       "      <td>4.809071e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153157</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>6.862703e-05</td>\n",
       "      <td>2.781587e-03</td>\n",
       "      <td>1.179880e-05</td>\n",
       "      <td>3.243649e-03</td>\n",
       "      <td>7.935687e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153158</th>\n",
       "      <td>fffc2b34bbe61c8d</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>1.386410e-07</td>\n",
       "      <td>2.823200e-05</td>\n",
       "      <td>1.699878e-08</td>\n",
       "      <td>1.755429e-05</td>\n",
       "      <td>2.093994e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffc489742ffe69b</td>\n",
       "      <td>0.026898</td>\n",
       "      <td>9.791380e-06</td>\n",
       "      <td>4.405036e-03</td>\n",
       "      <td>6.685259e-07</td>\n",
       "      <td>4.756990e-03</td>\n",
       "      <td>8.378789e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.013941</td>\n",
       "      <td>8.379217e-07</td>\n",
       "      <td>9.899017e-04</td>\n",
       "      <td>5.226643e-08</td>\n",
       "      <td>6.337216e-04</td>\n",
       "      <td>1.211765e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>1.263180e-06</td>\n",
       "      <td>4.128638e-04</td>\n",
       "      <td>1.298726e-07</td>\n",
       "      <td>3.184384e-04</td>\n",
       "      <td>2.061292e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>4.484265e-08</td>\n",
       "      <td>1.721906e-05</td>\n",
       "      <td>4.347290e-09</td>\n",
       "      <td>1.484443e-05</td>\n",
       "      <td>7.310650e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>3.287415e-09</td>\n",
       "      <td>5.576544e-06</td>\n",
       "      <td>3.498356e-10</td>\n",
       "      <td>4.531021e-06</td>\n",
       "      <td>1.604143e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153164</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.028332</td>\n",
       "      <td>3.646802e-07</td>\n",
       "      <td>1.218377e-03</td>\n",
       "      <td>2.575775e-08</td>\n",
       "      <td>9.019659e-04</td>\n",
       "      <td>5.781542e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic       obscene        threat  \\\n",
       "1       00001cee341fdb12  0.401214  4.801955e-07  2.293768e-02  3.035624e-09   \n",
       "2       0000247867823ef7  0.000854  1.126907e-06  1.285176e-04  1.265841e-07   \n",
       "3       00013b17ad220c46  0.110318  7.497661e-03  6.060326e-02  1.944498e-03   \n",
       "4       00017563c3f7919a  0.000071  2.055300e-09  4.193695e-06  7.595696e-11   \n",
       "5       00017695ad8997eb  0.005842  2.354547e-05  1.500915e-03  2.695010e-06   \n",
       "6       0001ea8717f6de06  0.000396  2.649962e-08  2.843496e-05  2.190758e-09   \n",
       "7       00024115d4cbde0f  0.000057  9.143020e-10  3.753479e-06  2.871155e-11   \n",
       "8       000247e83dcc1211  0.060142  3.967158e-05  8.073634e-03  5.068992e-06   \n",
       "9       00025358d4737918  0.000110  9.945701e-10  4.062479e-06  6.163175e-11   \n",
       "10      00026d1092fe71cc  0.000086  6.547442e-09  7.491110e-06  6.159895e-10   \n",
       "11      0002eadc3b301559  0.001783  8.607847e-09  8.376933e-05  4.346382e-10   \n",
       "12      0002f87b16116a7f  0.000226  3.450315e-09  1.069713e-05  1.779022e-10   \n",
       "13      0003806b11932181  0.000045  6.409742e-10  2.027266e-06  3.137825e-11   \n",
       "14      0003e1cccfd5a40a  0.000291  4.938336e-08  3.452524e-05  2.992070e-09   \n",
       "15      00059ace3e3e9a53  0.000011  8.643334e-11  4.761840e-07  4.216301e-12   \n",
       "16      000634272d0d44eb  0.004000  6.493673e-06  7.395913e-04  1.117532e-06   \n",
       "17      000663aff0fffc80  0.034875  4.397730e-04  1.235974e-02  7.057744e-05   \n",
       "18      000689dd34e20979  0.000933  7.692581e-08  7.174434e-05  6.084539e-09   \n",
       "19      000834769115370c  0.000009  2.899354e-12  1.812908e-07  5.221108e-14   \n",
       "20      000844b52dee5f3f  0.006392  6.720759e-06  1.145694e-03  3.610099e-07   \n",
       "21      00084da5d4ead7aa  0.013630  5.500105e-05  3.404537e-03  8.153383e-06   \n",
       "22      00091c35fa9d0465  0.008876  9.759446e-06  9.071497e-04  1.673874e-06   \n",
       "23      000968ce11f5ee34  0.001564  4.066731e-08  9.450634e-05  1.931657e-09   \n",
       "24      0009734200a85047  0.000385  3.421008e-07  5.777983e-05  3.754767e-08   \n",
       "25      00097b6214686db5  0.003905  1.039569e-07  2.632847e-04  6.064824e-09   \n",
       "26      0009aef4bd9e1697  0.000010  3.786042e-10  6.220546e-07  2.966246e-11   \n",
       "27      000a02d807ae0254  0.001420  3.318503e-07  1.683112e-04  3.735080e-08   \n",
       "28      000a6c6d4e89b9bc  0.022232  1.435713e-04  4.948179e-03  2.648273e-05   \n",
       "29      000bafe2080bba82  0.002749  1.270082e-07  1.510442e-04  6.017970e-09   \n",
       "30      000bf0a9894b2807  0.000039  3.135608e-10  1.688038e-06  1.210374e-11   \n",
       "...                  ...       ...           ...           ...           ...   \n",
       "153135  fff3ae2e177b6bb3  0.000156  1.749234e-09  6.331375e-06  8.362236e-11   \n",
       "153136  fff4109e837f7acc  0.003048  7.577678e-06  6.145186e-04  7.277430e-07   \n",
       "153137  fff4373a81ef9f2a  0.000056  1.026127e-09  3.586931e-06  4.946327e-11   \n",
       "153138  fff460574ddbcd80  0.009341  7.012262e-06  1.376750e-03  8.310382e-07   \n",
       "153139  fff4fc0a1555be5c  0.000219  1.560590e-08  1.777961e-05  8.412163e-10   \n",
       "153140  fff5b9bb944d634c  0.001449  2.293349e-07  1.719517e-04  9.629429e-09   \n",
       "153141  fff5c4a77fe0c05f  0.001038  2.495729e-07  1.458753e-04  1.871546e-08   \n",
       "153142  fff5fb61bd637c82  0.000040  2.059179e-09  2.448874e-06  1.531766e-10   \n",
       "153143  fff69311f306df44  0.005543  5.560698e-05  1.389613e-03  8.751502e-06   \n",
       "153144  fff6ad63666fb304  0.620878  1.893717e-03  2.382147e-01  3.253189e-05   \n",
       "153145  fff7159b3ee95618  0.000737  5.647543e-08  6.090402e-05  2.842595e-09   \n",
       "153146  fff718ffe5f05559  0.000447  1.975964e-07  5.063397e-05  2.008588e-08   \n",
       "153147  fff7fc22a0cdccd3  0.000010  3.364876e-11  4.145574e-07  1.202532e-12   \n",
       "153148  fff83b80284d8440  0.007192  7.437673e-06  9.055402e-04  4.436586e-07   \n",
       "153149  fff8ef316d0c6990  0.002182  8.656997e-07  1.752051e-04  9.904686e-08   \n",
       "153150  fff8f521a7dbcd47  0.042013  8.628015e-05  5.418150e-03  6.060350e-06   \n",
       "153151  fff8f64043129fa2  0.000171  8.011449e-10  7.100787e-06  2.510854e-11   \n",
       "153152  fff9d70fe0722906  0.117855  2.478148e-04  2.472171e-02  2.071025e-05   \n",
       "153153  fff9fa508f400ee6  0.017155  1.440540e-05  3.599483e-03  1.264856e-06   \n",
       "153154  fffa3fae1890b40a  0.001709  1.135558e-08  6.008503e-05  4.808189e-10   \n",
       "153155  fffa8a11c4378854  0.032229  1.399145e-05  2.324078e-03  1.066581e-06   \n",
       "153156  fffac2a094c8e0e2  0.218863  5.479940e-06  2.239193e-02  7.624137e-08   \n",
       "153157  fffb5451268fb5ba  0.021159  6.862703e-05  2.781587e-03  1.179880e-05   \n",
       "153158  fffc2b34bbe61c8d  0.000275  1.386410e-07  2.823200e-05  1.699878e-08   \n",
       "153159  fffc489742ffe69b  0.026898  9.791380e-06  4.405036e-03  6.685259e-07   \n",
       "153160  fffcd0960ee309b5  0.013941  8.379217e-07  9.899017e-04  5.226643e-08   \n",
       "153161  fffd7a9a6eb32c16  0.003385  1.263180e-06  4.128638e-04  1.298726e-07   \n",
       "153162  fffda9e8d6fafa9e  0.000203  4.484265e-08  1.721906e-05  4.347290e-09   \n",
       "153163  fffe8f1340a79fc2  0.000140  3.287415e-09  5.576544e-06  3.498356e-10   \n",
       "153164  ffffce3fb183ee80  0.028332  3.646802e-07  1.218377e-03  2.575775e-08   \n",
       "\n",
       "              insult  identity_hate  \n",
       "1       6.842720e-03   4.848761e-07  \n",
       "2       1.037182e-04   1.525776e-06  \n",
       "3       5.686125e-02   7.324074e-03  \n",
       "4       3.228442e-06   1.559327e-09  \n",
       "5       1.224030e-03   1.932940e-05  \n",
       "6       2.418763e-05   3.822227e-08  \n",
       "7       2.464680e-06   9.004787e-10  \n",
       "8       7.758652e-03   4.161255e-05  \n",
       "9       2.477330e-06   1.468281e-09  \n",
       "10      5.475115e-06   9.274395e-09  \n",
       "11      3.948727e-05   1.900641e-08  \n",
       "12      7.646419e-06   7.251321e-09  \n",
       "13      1.205619e-06   5.328110e-10  \n",
       "14      1.889621e-05   6.576210e-08  \n",
       "15      2.985132e-07   1.051656e-10  \n",
       "16      6.316192e-04   9.959475e-06  \n",
       "17      1.078983e-02   4.927785e-04  \n",
       "18      5.386529e-05   1.394492e-07  \n",
       "19      8.443901e-08   4.096484e-12  \n",
       "20      9.506065e-04   5.387312e-06  \n",
       "21      2.683688e-03   4.128559e-05  \n",
       "22      7.593932e-04   2.045658e-05  \n",
       "23      7.171904e-05   6.780058e-08  \n",
       "24      4.473262e-05   4.604294e-07  \n",
       "25      1.549245e-04   1.613602e-07  \n",
       "26      4.557426e-07   6.199944e-10  \n",
       "27      1.084763e-04   5.204718e-07  \n",
       "28      4.022649e-03   1.602446e-04  \n",
       "29      1.330725e-04   6.311305e-07  \n",
       "30      1.268879e-06   5.214625e-10  \n",
       "...              ...            ...  \n",
       "153135  4.605520e-06   3.057887e-09  \n",
       "153136  4.150901e-04   8.769886e-06  \n",
       "153137  2.522530e-06   1.894806e-09  \n",
       "153138  1.092258e-03   1.077599e-05  \n",
       "153139  1.193501e-05   2.156232e-08  \n",
       "153140  1.157330e-04   3.046453e-07  \n",
       "153141  9.190113e-05   3.161311e-07  \n",
       "153142  1.598501e-06   2.456769e-09  \n",
       "153143  1.799283e-03   6.912105e-05  \n",
       "153144  1.116350e-01   5.117248e-04  \n",
       "153145  3.605537e-05   8.551762e-08  \n",
       "153146  4.032894e-05   3.424879e-07  \n",
       "153147  2.698844e-07   4.959495e-11  \n",
       "153148  8.235147e-04   4.918661e-06  \n",
       "153149  1.534591e-04   1.257561e-06  \n",
       "153150  5.061413e-03   4.552823e-05  \n",
       "153151  4.227538e-06   1.175081e-09  \n",
       "153152  1.810628e-02   1.684519e-04  \n",
       "153153  1.668745e-03   1.219323e-05  \n",
       "153154  3.897803e-05   1.503420e-08  \n",
       "153155  2.334242e-03   2.803831e-05  \n",
       "153156  9.388320e-03   4.809071e-06  \n",
       "153157  3.243649e-03   7.935687e-05  \n",
       "153158  1.755429e-05   2.093994e-07  \n",
       "153159  4.756990e-03   8.378789e-06  \n",
       "153160  6.337216e-04   1.211765e-06  \n",
       "153161  3.184384e-04   2.061292e-06  \n",
       "153162  1.484443e-05   7.310650e-08  \n",
       "153163  4.531021e-06   1.604143e-08  \n",
       "153164  9.019659e-04   5.781542e-07  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_gen_kaggle_sub(df['comment_text'], df_test['comment_text'], labels.drop('id', axis=1), save_path01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gen_all_predictions(ft, lbs, test_df):\n",
    "    \"\"\"\n",
    "    Description of function\n",
    "    \n",
    "    Args:\n",
    "        ft (type_of_ft): Description of ft\n",
    "        lbs (type_of_lbs): Description of lbs\n",
    "        \n",
    "    Returns\n",
    "        (Type of return) Description of return\n",
    "    \n",
    "    \"\"\"\n",
    "    vectorizer2 = TfidfVectorizer(min_df=0.001, stop_words = 'english')\n",
    "    X = vectorizer2.fit_transform(ft)\n",
    "    ft_test = test_df['comment_text']    \n",
    "    Xte = vectorizer2.transform(ft_test)\n",
    "    \n",
    "    lb_proba = []\n",
    "    for label in tqdm(lbs.columns):\n",
    "        y = lbs[label]\n",
    "#         Xtr, Xte, ytr, yte = train_test_split(X, y)\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        # Make prediction on test set and return the highest probability        \n",
    "        pred_result = clf.predict_proba(Xte)\n",
    "        prob = pred_result[:, 1]\n",
    "        lb_proba.append(prob)\n",
    "\n",
    "    return lb_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA = pd.DataFrame(_gen_all_predictions(feature, labels.drop('id', axis=1), df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA.T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBB = AAA.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBB.columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']\n",
    "BBB.insert(0, 'id', df_test['id'], True)\n",
    "BBB.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBB.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 7)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BBB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a path to submission file\n",
    "save_path = join('..', 'Results', 'simple_subm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_kaggle_submission(ft, lbs, test_df, save_path):\n",
    "    raw_pred_df = pd.DataFrame(_gen_all_predictions(ft, lbs.drop('id', axis=1), test_df))\n",
    "    sub_df = raw_pred_df.T\n",
    "    sub_df.columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult','identity_hate']\n",
    "    sub_df.insert(0, 'id', df_test['id'], True)\n",
    "    sub_df.index += 1 \n",
    "    \n",
    "    sub_df.to_csv(save_path, index = False)\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6/6 [00:00<00:00, 13.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.997059</td>\n",
       "      <td>0.552809</td>\n",
       "      <td>0.993161</td>\n",
       "      <td>0.034322</td>\n",
       "      <td>0.978686</td>\n",
       "      <td>0.499119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.017104</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.002858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.028479</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>0.001526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.009361</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>0.000524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.060022</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.021797</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>0.020556</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>0.454314</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>0.210251</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.238466</td>\n",
       "      <td>0.016933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>0.023433</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.008921</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.001274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>0.010371</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002eadc3b301559</td>\n",
       "      <td>0.193590</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.063449</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.038223</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>0.044478</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.002881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003806b11932181</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>0.012199</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.007456</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.001204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000634272d0d44eb</td>\n",
       "      <td>0.040879</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.018207</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.016915</td>\n",
       "      <td>0.003925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000663aff0fffc80</td>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000689dd34e20979</td>\n",
       "      <td>0.123490</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.045158</td>\n",
       "      <td>0.008430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000834769115370c</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000844b52dee5f3f</td>\n",
       "      <td>0.067606</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.031455</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.030051</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00084da5d4ead7aa</td>\n",
       "      <td>0.101165</td>\n",
       "      <td>0.007755</td>\n",
       "      <td>0.056951</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.050729</td>\n",
       "      <td>0.005070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00091c35fa9d0465</td>\n",
       "      <td>0.382641</td>\n",
       "      <td>0.061977</td>\n",
       "      <td>0.143606</td>\n",
       "      <td>0.041274</td>\n",
       "      <td>0.144859</td>\n",
       "      <td>0.114904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000968ce11f5ee34</td>\n",
       "      <td>0.057280</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.024376</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.023115</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0009734200a85047</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.006187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00097b6214686db5</td>\n",
       "      <td>0.066796</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.031983</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.025717</td>\n",
       "      <td>0.005425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0009aef4bd9e1697</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.004174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000a02d807ae0254</td>\n",
       "      <td>0.043454</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.016629</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.013477</td>\n",
       "      <td>0.001363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000a6c6d4e89b9bc</td>\n",
       "      <td>0.088689</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.037403</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.041269</td>\n",
       "      <td>0.012560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000bafe2080bba82</td>\n",
       "      <td>0.219863</td>\n",
       "      <td>0.014410</td>\n",
       "      <td>0.077028</td>\n",
       "      <td>0.006632</td>\n",
       "      <td>0.085947</td>\n",
       "      <td>0.082639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>000bf0a9894b2807</td>\n",
       "      <td>0.022828</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.012277</td>\n",
       "      <td>0.002990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153135</th>\n",
       "      <td>fff3ae2e177b6bb3</td>\n",
       "      <td>0.028111</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.001908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153136</th>\n",
       "      <td>fff4109e837f7acc</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.011809</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.008371</td>\n",
       "      <td>0.004450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153137</th>\n",
       "      <td>fff4373a81ef9f2a</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.000635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153138</th>\n",
       "      <td>fff460574ddbcd80</td>\n",
       "      <td>0.226034</td>\n",
       "      <td>0.013946</td>\n",
       "      <td>0.124907</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.089473</td>\n",
       "      <td>0.030287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153139</th>\n",
       "      <td>fff4fc0a1555be5c</td>\n",
       "      <td>0.023297</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.014859</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>0.007163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153140</th>\n",
       "      <td>fff5b9bb944d634c</td>\n",
       "      <td>0.035597</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.013881</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.010564</td>\n",
       "      <td>0.001038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153141</th>\n",
       "      <td>fff5c4a77fe0c05f</td>\n",
       "      <td>0.021758</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.000948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153142</th>\n",
       "      <td>fff5fb61bd637c82</td>\n",
       "      <td>0.005947</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153143</th>\n",
       "      <td>fff69311f306df44</td>\n",
       "      <td>0.063394</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.032754</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.033740</td>\n",
       "      <td>0.009594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153144</th>\n",
       "      <td>fff6ad63666fb304</td>\n",
       "      <td>0.933981</td>\n",
       "      <td>0.229242</td>\n",
       "      <td>0.843291</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.713574</td>\n",
       "      <td>0.089605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153145</th>\n",
       "      <td>fff7159b3ee95618</td>\n",
       "      <td>0.028605</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.007831</td>\n",
       "      <td>0.002178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153146</th>\n",
       "      <td>fff718ffe5f05559</td>\n",
       "      <td>0.009828</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.003939</td>\n",
       "      <td>0.001910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153147</th>\n",
       "      <td>fff7fc22a0cdccd3</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153148</th>\n",
       "      <td>fff83b80284d8440</td>\n",
       "      <td>0.027572</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.012598</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.013790</td>\n",
       "      <td>0.001739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153149</th>\n",
       "      <td>fff8ef316d0c6990</td>\n",
       "      <td>0.019833</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.000541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>fff8f521a7dbcd47</td>\n",
       "      <td>0.272754</td>\n",
       "      <td>0.027129</td>\n",
       "      <td>0.106930</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.108882</td>\n",
       "      <td>0.009523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.000473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153152</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>0.560365</td>\n",
       "      <td>0.023915</td>\n",
       "      <td>0.309346</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.240816</td>\n",
       "      <td>0.013445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153153</th>\n",
       "      <td>fff9fa508f400ee6</td>\n",
       "      <td>0.373457</td>\n",
       "      <td>0.011121</td>\n",
       "      <td>0.218025</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.107943</td>\n",
       "      <td>0.010213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>fffa3fae1890b40a</td>\n",
       "      <td>0.522667</td>\n",
       "      <td>0.027776</td>\n",
       "      <td>0.272441</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.208249</td>\n",
       "      <td>0.029256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>0.248271</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.074788</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.079037</td>\n",
       "      <td>0.010725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>0.934144</td>\n",
       "      <td>0.136709</td>\n",
       "      <td>0.872707</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.807686</td>\n",
       "      <td>0.087555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153157</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>0.047781</td>\n",
       "      <td>0.011754</td>\n",
       "      <td>0.018243</td>\n",
       "      <td>0.005546</td>\n",
       "      <td>0.023755</td>\n",
       "      <td>0.013272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153158</th>\n",
       "      <td>fffc2b34bbe61c8d</td>\n",
       "      <td>0.017263</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.009297</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>0.003552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffc489742ffe69b</td>\n",
       "      <td>0.294968</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.102264</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.139493</td>\n",
       "      <td>0.004207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.282086</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.073780</td>\n",
       "      <td>0.004203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.101222</td>\n",
       "      <td>0.014902</td>\n",
       "      <td>0.051840</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.056542</td>\n",
       "      <td>0.025625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.003179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.015974</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.017605</td>\n",
       "      <td>0.021354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153164</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.710815</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.401995</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.310555</td>\n",
       "      <td>0.011372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic   obscene    threat  \\\n",
       "1       00001cee341fdb12  0.997059      0.552809  0.993161  0.034322   \n",
       "2       0000247867823ef7  0.017104      0.002524  0.007965  0.001360   \n",
       "3       00013b17ad220c46  0.028479      0.000969  0.012154  0.000284   \n",
       "4       00017563c3f7919a  0.009361      0.000825  0.004365  0.000221   \n",
       "5       00017695ad8997eb  0.060022      0.001280  0.024679  0.000238   \n",
       "6       0001ea8717f6de06  0.020556      0.000749  0.007816  0.000270   \n",
       "7       00024115d4cbde0f  0.009431      0.000249  0.004904  0.000043   \n",
       "8       000247e83dcc1211  0.454314      0.015219  0.210251  0.006094   \n",
       "9       00025358d4737918  0.023433      0.000845  0.008921  0.000616   \n",
       "10      00026d1092fe71cc  0.010371      0.000864  0.006145  0.000554   \n",
       "11      0002eadc3b301559  0.193590      0.001063  0.063449  0.000464   \n",
       "12      0002f87b16116a7f  0.044478      0.001202  0.012997  0.000594   \n",
       "13      0003806b11932181  0.010945      0.000449  0.003784  0.000147   \n",
       "14      0003e1cccfd5a40a  0.012199      0.001061  0.007456  0.000367   \n",
       "15      00059ace3e3e9a53  0.004261      0.000263  0.001785  0.000111   \n",
       "16      000634272d0d44eb  0.040879      0.002604  0.018207  0.002207   \n",
       "17      000663aff0fffc80  0.095844      0.009996  0.052948  0.002996   \n",
       "18      000689dd34e20979  0.123490      0.003735  0.047380  0.001727   \n",
       "19      000834769115370c  0.009272      0.000093  0.002597  0.000018   \n",
       "20      000844b52dee5f3f  0.067606      0.002008  0.031455  0.000210   \n",
       "21      00084da5d4ead7aa  0.101165      0.007755  0.056951  0.002442   \n",
       "22      00091c35fa9d0465  0.382641      0.061977  0.143606  0.041274   \n",
       "23      000968ce11f5ee34  0.057280      0.001180  0.024376  0.000113   \n",
       "24      0009734200a85047  0.012436      0.004137  0.007525  0.003580   \n",
       "25      00097b6214686db5  0.066796      0.002871  0.031983  0.001026   \n",
       "26      0009aef4bd9e1697  0.003566      0.002388  0.002785  0.002762   \n",
       "27      000a02d807ae0254  0.043454      0.000787  0.016629  0.000370   \n",
       "28      000a6c6d4e89b9bc  0.088689      0.008592  0.037403  0.003946   \n",
       "29      000bafe2080bba82  0.219863      0.014410  0.077028  0.006632   \n",
       "30      000bf0a9894b2807  0.022828      0.002279  0.011405  0.001374   \n",
       "...                  ...       ...           ...       ...       ...   \n",
       "153135  fff3ae2e177b6bb3  0.028111      0.001082  0.008481  0.000718   \n",
       "153136  fff4109e837f7acc  0.019830      0.003063  0.011809  0.001329   \n",
       "153137  fff4373a81ef9f2a  0.008673      0.000523  0.003516  0.000321   \n",
       "153138  fff460574ddbcd80  0.226034      0.013946  0.124907  0.005680   \n",
       "153139  fff4fc0a1555be5c  0.023297      0.008015  0.014859  0.003356   \n",
       "153140  fff5b9bb944d634c  0.035597      0.000775  0.013881  0.000105   \n",
       "153141  fff5c4a77fe0c05f  0.021758      0.000868  0.012451  0.000176   \n",
       "153142  fff5fb61bd637c82  0.005947      0.000676  0.002649  0.000346   \n",
       "153143  fff69311f306df44  0.063394      0.010821  0.032754  0.003975   \n",
       "153144  fff6ad63666fb304  0.933981      0.229242  0.843291  0.010349   \n",
       "153145  fff7159b3ee95618  0.028605      0.001202  0.012592  0.000391   \n",
       "153146  fff718ffe5f05559  0.009828      0.000876  0.004215  0.000519   \n",
       "153147  fff7fc22a0cdccd3  0.004678      0.000160  0.002663  0.000056   \n",
       "153148  fff83b80284d8440  0.027572      0.002089  0.012598  0.000633   \n",
       "153149  fff8ef316d0c6990  0.019833      0.000612  0.009143  0.000289   \n",
       "153150  fff8f521a7dbcd47  0.272754      0.027129  0.106930  0.003334   \n",
       "153151  fff8f64043129fa2  0.007281      0.000285  0.002443  0.000189   \n",
       "153152  fff9d70fe0722906  0.560365      0.023915  0.309346  0.002575   \n",
       "153153  fff9fa508f400ee6  0.373457      0.011121  0.218025  0.002923   \n",
       "153154  fffa3fae1890b40a  0.522667      0.027776  0.272441  0.015656   \n",
       "153155  fffa8a11c4378854  0.248271      0.005910  0.074788  0.002120   \n",
       "153156  fffac2a094c8e0e2  0.934144      0.136709  0.872707  0.005615   \n",
       "153157  fffb5451268fb5ba  0.047781      0.011754  0.018243  0.005546   \n",
       "153158  fffc2b34bbe61c8d  0.017263      0.003069  0.009297  0.002064   \n",
       "153159  fffc489742ffe69b  0.294968      0.005599  0.102264  0.000845   \n",
       "153160  fffcd0960ee309b5  0.282086      0.003402  0.097100  0.001125   \n",
       "153161  fffd7a9a6eb32c16  0.101222      0.014902  0.051840  0.009860   \n",
       "153162  fffda9e8d6fafa9e  0.007438      0.001558  0.003559  0.001389   \n",
       "153163  fffe8f1340a79fc2  0.038829      0.003042  0.015974  0.003179   \n",
       "153164  ffffce3fb183ee80  0.710815      0.006724  0.401995  0.002549   \n",
       "\n",
       "          insult  identity_hate  \n",
       "1       0.978686       0.499119  \n",
       "2       0.008103       0.002858  \n",
       "3       0.011852       0.001526  \n",
       "4       0.004474       0.000524  \n",
       "5       0.021797       0.000992  \n",
       "6       0.008260       0.000792  \n",
       "7       0.003987       0.000185  \n",
       "8       0.238466       0.016933  \n",
       "9       0.007025       0.001274  \n",
       "10      0.005083       0.001214  \n",
       "11      0.038223       0.002009  \n",
       "12      0.011811       0.002881  \n",
       "13      0.003813       0.000253  \n",
       "14      0.005133       0.001204  \n",
       "15      0.001749       0.000266  \n",
       "16      0.016915       0.003925  \n",
       "17      0.049364       0.008805  \n",
       "18      0.045158       0.008430  \n",
       "19      0.001780       0.000075  \n",
       "20      0.030051       0.001339  \n",
       "21      0.050729       0.005070  \n",
       "22      0.144859       0.114904  \n",
       "23      0.023115       0.000788  \n",
       "24      0.006323       0.006187  \n",
       "25      0.025717       0.005425  \n",
       "26      0.002531       0.004174  \n",
       "27      0.013477       0.001363  \n",
       "28      0.041269       0.012560  \n",
       "29      0.085947       0.082639  \n",
       "30      0.012277       0.002990  \n",
       "...          ...            ...  \n",
       "153135  0.007610       0.001908  \n",
       "153136  0.008371       0.004450  \n",
       "153137  0.003281       0.000635  \n",
       "153138  0.089473       0.030287  \n",
       "153139  0.013191       0.007163  \n",
       "153140  0.010564       0.001038  \n",
       "153141  0.008716       0.000948  \n",
       "153142  0.002422       0.000668  \n",
       "153143  0.033740       0.009594  \n",
       "153144  0.713574       0.089605  \n",
       "153145  0.007831       0.002178  \n",
       "153146  0.003939       0.001910  \n",
       "153147  0.002470       0.000183  \n",
       "153148  0.013790       0.001739  \n",
       "153149  0.008647       0.000541  \n",
       "153150  0.108882       0.009523  \n",
       "153151  0.002644       0.000473  \n",
       "153152  0.240816       0.013445  \n",
       "153153  0.107943       0.010213  \n",
       "153154  0.208249       0.029256  \n",
       "153155  0.079037       0.010725  \n",
       "153156  0.807686       0.087555  \n",
       "153157  0.023755       0.013272  \n",
       "153158  0.006515       0.003552  \n",
       "153159  0.139493       0.004207  \n",
       "153160  0.073780       0.004203  \n",
       "153161  0.056542       0.025625  \n",
       "153162  0.004250       0.003179  \n",
       "153163  0.017605       0.021354  \n",
       "153164  0.310555       0.011372  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_kaggle_submission(feature, labels, df_test, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bala = feature[:5]\n",
    "bala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tknz():\n",
    "    \n",
    "    def __init__(self, comments):\n",
    "        self.comments = comments\n",
    "        \n",
    "    def get_tknized(comments):   \n",
    "        \"\"\" \n",
    "        Create a nested list of tokenized comments\n",
    "        Input: a series of text comments\n",
    "        Returns: a nested list of words of each comment\n",
    "        \"\"\"\n",
    "        com_tok = []\n",
    "        for i in range(len(comments)):\n",
    "            com = regexp_tokenize(comments[i], '[\\S]+')\n",
    "            com_tok.append(com)\n",
    "        return com_tok\n",
    "\n",
    "    def get_max_com_len(com_tok):   \n",
    "        \"\"\" \n",
    "        Get list of comment's lenghths\n",
    "        Input: a nested list of tokenized comments\n",
    "        Returns: \n",
    "            - len_com: a list of respective lengths\n",
    "            - max_len: lenghth of the longest comment\n",
    "        \"\"\"\n",
    "        len_com = []\n",
    "        for i in com_tok:\n",
    "            l = len(i)\n",
    "            len_com.append(l)\n",
    "        max_com_len = max(len_com)\n",
    "        return len_com, max_com_len\n",
    "    \n",
    "    def get_max_tok_len(com_tok):\n",
    "        \"\"\"\n",
    "        Get the length of the longest tokens for empty string initilization\n",
    "        Input: a nested list of tokenized comments\n",
    "        Returns: (int) lenghth of longest tokens\n",
    "        \"\"\"\n",
    "        q = []\n",
    "        for i in range(len(com_tok)):\n",
    "            for j in range(len(com_tok[i])):\n",
    "                #List of every single element's length\n",
    "                q += [len(com_tok[i][j])]\n",
    "                max_tok_len = max(q)\n",
    "        return max_tok_len\n",
    "    \n",
    "    def gen_com_array(comments, max_len, max_tok_len):\n",
    "        \"\"\"\n",
    "        Create an array of shape number of comments x length of max comment\n",
    "        Input: \n",
    "        - A series of comments\n",
    "        - Lenghth of longest comment\n",
    "        - Lenght of longest token\n",
    "        Returns: an array with tokens of each comment as a dimension\n",
    "        \"\"\"\n",
    "        \n",
    "        #Initialize a zero array\n",
    "        full_arr = np.zeros((len(comments), max_len), dtype = f'U{max_tok_len}')\n",
    "        \n",
    "        # Fill array with tokenized comments, one for each dimension\n",
    "        for i in range(len(comments)):\n",
    "            for j in range(max_len):\n",
    "                max_com = com_tok[i]\n",
    "                a = np.pad(max_com, (0, max_len-len(max_com)), 'constant', constant_values = np.nan)\n",
    "            full_arr[i] = a\n",
    "        return full_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my',\n",
       "        'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted?',\n",
       "        'They', \"weren't\", 'vandalisms,', 'just', 'closure', 'on',\n",
       "        'some', 'GAs', 'after', 'I', 'voted', 'at', 'New', 'York',\n",
       "        'Dolls', 'FAC.', 'And', 'please', \"don't\", 'remove', 'the',\n",
       "        'template', 'from', 'the', 'talk', 'page', 'since', \"I'm\",\n",
       "        'retired', 'now.89.205.38.27', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan'],\n",
       "       [\"D'aww!\", 'He', 'matches', 'this', 'background', 'colour', \"I'm\",\n",
       "        'seemingly', 'stuck', 'with.', 'Thanks.', '(talk)', '21:51,',\n",
       "        'January', '11,', '2016', '(UTC)', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan'],\n",
       "       ['Hey', 'man,', \"I'm\", 'really', 'not', 'trying', 'to', 'edit',\n",
       "        'war.', \"It's\", 'just', 'that', 'this', 'guy', 'is',\n",
       "        'constantly', 'removing', 'relevant', 'information', 'and',\n",
       "        'talking', 'to', 'me', 'through', 'edits', 'instead', 'of', 'my',\n",
       "        'talk', 'page.', 'He', 'seems', 'to', 'care', 'more', 'about',\n",
       "        'the', 'formatting', 'than', 'the', 'actual', 'info.', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan'],\n",
       "       ['\"', 'More', 'I', \"can't\", 'make', 'any', 'real', 'suggestions',\n",
       "        'on', 'improvement', '-', 'I', 'wondered', 'if', 'the',\n",
       "        'section', 'statistics', 'should', 'be', 'later', 'on,', 'or',\n",
       "        'a', 'subsection', 'of', '\"\"types', 'of', 'accidents\"\"', '-I',\n",
       "        'think', 'the', 'references', 'may', 'need', 'tidying', 'so',\n",
       "        'that', 'they', 'are', 'all', 'in', 'the', 'exact', 'same',\n",
       "        'format', 'ie', 'date', 'format', 'etc.', 'I', 'can', 'do',\n",
       "        'that', 'later', 'on,', 'if', 'no-one', 'else', 'does', 'first',\n",
       "        '-', 'if', 'you', 'have', 'any', 'preferences', 'for',\n",
       "        'formatting', 'style', 'on', 'references', 'or', 'want', 'to',\n",
       "        'do', 'it', 'yourself', 'please', 'let', 'me', 'know.', 'There',\n",
       "        'appears', 'to', 'be', 'a', 'backlog', 'on', 'articles', 'for',\n",
       "        'review', 'so', 'I', 'guess', 'there', 'may', 'be', 'a', 'delay',\n",
       "        'until', 'a', 'reviewer', 'turns', 'up.', \"It's\", 'listed', 'in',\n",
       "        'the', 'relevant', 'form', 'eg',\n",
       "        'Wikipedia:Good_article_nominations#Transport', '\"'],\n",
       "       ['You,', 'sir,', 'are', 'my', 'hero.', 'Any', 'chance', 'you',\n",
       "        'remember', 'what', 'page', \"that's\", 'on?', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan',\n",
       "        'nan', 'nan', 'nan', 'nan', 'nan', 'nan', 'nan']], dtype='<U44')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_tok = Tknz.get_tknized(bala)\n",
    "len_com, max_com_len = Tknz.get_max_com_len(com_tok)\n",
    "max_tok_len = Tknz.get_max_tok_len(com_tok)\n",
    "ar_01 = Tknz.gen_com_array(bala, max_com_len, max_tok_len)\n",
    "ar_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vuquy\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "sentences = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
    "\n",
    "model = FastText(sentences, min_count=1)\n",
    "say_vector = model.wv['say']  # get vector for word\n",
    "of_vector = model.wv['of']  # get vector for out-of-vocab word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
